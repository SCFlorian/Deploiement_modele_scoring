---
title: Deploiement Modele Scoring
emoji: ğŸ’»
colorFrom: green
colorTo: gray
sdk: docker
pinned: false
---
# ğŸ“Š DÃ©ploiement d'un modÃ¨le de scoring
---
## Description
PrÃ©cÃ©demment nous avons rÃ©alisÃ© un modÃ¨le de scoring en partant du projet Home Credit Default Risk de Kaggle. Nous allons reprendre le meilleur modÃ¨le de ce projet afin de le dÃ©ployer.

## Objectifs 

Les objectifs sont les suivants :
- un historique des versions
- une API fonctionnelle -> FastAPI avec une interface rÃ©alisÃ©e avec Gradio
- des tests unintaires automatisÃ©s
- un dockerfile
- Une analyse du Data Drift -> RÃ©alisÃ©e avec EvidentlyAI
- Un dashboard avec Streamlit
- une solution de stockage des donnÃ©es en production
- un pipeline CI/CD
- une documentation README

## DonnÃ©es utilisÃ©es
- Les donnÃ©es de base viennent du projet Kaggle :

https://www.kaggle.com/c/home-credit-default-risk/data

## Organisation du projet
### En local
```
â”œâ”€â”€ .github/workflows
â”‚   â”œâ”€â”€cicd.yaml
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ example_input.csv # Nouveaux clients Ã  tester
â”‚   â””â”€â”€ train_df.csv      # DonnÃ©es d'entraÃ®nement / Fichier prÃ©sent uniquement en local car volumineux
â”‚
â”œâ”€â”€ database      
â”‚   â”œâ”€â”€ create_db.py     # CrÃ©ation des tables de la BDD
â”‚
â”œâ”€â”€ models/        
â”‚   â”œâ”€â”€ expected_columns.json
â”‚   â”œâ”€â”€ imputer_columns.json
â”‚   â”œâ”€â”€ threshold.txt
â”‚
â”œâ”€â”€ monitoring     # Dossier prÃ©sent uniquement en local car trop volumineux
â”‚   â”œâ”€â”€ dashboard_streamlit.py        # Tableaux de bord des indicateurs opÃ©rationnels
â”‚   â”œâ”€â”€ monitoring_evidentlyai.ipynb  # Anlayse du datadrift
â”‚   â”œâ”€â”€ cprofile.ipynb                # Optimisation du code sur la fonction prepare_client
â”‚   â”œâ”€â”€ cprofile_old.ipynb            # Fichier app avant optimisation du code
â”‚
â”œâ”€â”€ tests/        
â”‚   â”œâ”€â”€ test_basic.py
â”‚   â”œâ”€â”€ test_endpoints.py
â”‚   â”œâ”€â”€ test_model_full_dataset.py
â”‚ 
â”œâ”€â”€ .env     # PrÃ©sent uniquement en local car gÃ¨re les "secrets"
â”œâ”€â”€ .gitignore
â”œâ”€â”€ app.py        # Fichier app avant transformation
â”œâ”€â”€ app_old.py    # Fichier app aprÃ¨s transformation
â”œâ”€â”€ Dockerfile    # Conteneurisation
â”œâ”€â”€ README.md     # Documentation du projet
â”œâ”€â”€ poetry.lock
â””â”€â”€ pyproject.toml    # DÃ©pendances et configuration
```
### Dans un dÃ©pÃ´t Hugging Face
https://huggingface.co/FlorianSC/homecredit-scoring-artifacts
```
homecredit-scoring-artifacts
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ imputer_numeric.pkl
â”œâ”€â”€ pipeline_lightgbm.pkl
```
---

## Installation et utilisation

### Installation
1. Cloner le projet :
``` 
git clone git@github.com:SCFlorian/Deploiement_modele_scoring.git
cd Deploiement_modele_scoring
```
2. Installer les dÃ©pendances :
Le projet utilise pyproject.toml pour la gestion des dÃ©pendances.
```
poetry install
```
3. Ouvrir le projet dans VS Code :
```
code .
```
4. Configurer lâ€™environnement Python dans VS Code :
	1.	Installez lâ€™extension Python (si ce nâ€™est pas dÃ©jÃ  fait).
	2.	Appuyez sur Ctrl+Shift+P (Windows/Linux) ou Cmd+Shift+P (Mac).
	4.	Recherchez â€œPython: Select Interpreterâ€.
	5.	SÃ©lectionnez lâ€™environnement crÃ©Ã© par Poetry ou celui dans lequel tu as installÃ© le projet.

5. CrÃ©ation d'une base de donnÃ©es PostreSQL en local :
    1. Bien penser Ã  mettre dans ".env" l'URL de la base de donnÃ©es.
    2. La crÃ©ation des bases se rÃ©alise au lancement de l'API.
    3. CrÃ©ation de 4 tables.


### Utilisation de l'API en local

- GÃ©nÃ©rer l'environnement virtuel
```
poetry run uvicorn app:app --reload
```
- Ajouter l'URL sur un navigateur
```
http://127.0.0.1:8000
```

- L'ensemble des inputs et outputs seront enregistrÃ©s dans une base PostreSQL.

### Utilisation de l'API via Hugging Face

- Bien penser Ã  paramÃ©trer un token pour faire lien entre le projet GitHub et HF.
- Au lancement d'un 'push' sur main, il y a un dÃ©ploiement sur Hugging Face Spaces :
    - https://huggingface.co/spaces/FlorianSC/Deploiement_modele_scoring
- Pas de sauvegarde des informations avec HF, uniquement une interface opÃ©rationnelle.

#### CrÃ©ation d'un dashboard pour le monitoring opÃ©rationnel avec Streamlit
- GÃ©nÃ©rer l'environnement virtuel :
```
poetry run streamlit run monitoring/dashboard_streamlit.py
```
- Dashboard Streamlit

<img width="766" height="726" alt="Capture dâ€™eÌcran 2025-12-23 aÌ€ 11 16 51" src="https://github.com/user-attachments/assets/d684e0d7-566b-4c7f-8869-b7a19cda1dd2" />

On peut remarquer des temps plutÃ´t cohÃ©rent avec notre type de modÃ¨le :
    - Un temps d'infÃ©rence rapide.
    - La latence global et le temps CPU -> cohÃ©rence avec l'objectif du projet.

#### GÃ©nÃ©ration de l'analyse du datadrift
- Rapport EvidendlyAI

<img width="1274" height="645" alt="Capture dâ€™eÌcran 2025-12-23 aÌ€ 15 37 08" src="https://github.com/user-attachments/assets/7d987f90-0a71-4432-b443-dab032b18879" />

Pas de prÃ©sence d'un gros changement entre les donnÃ©es qui ont contribuÃ© Ã  l'entraÃ®nement et celles utilisÃ©es pour les nouveaux clients.

